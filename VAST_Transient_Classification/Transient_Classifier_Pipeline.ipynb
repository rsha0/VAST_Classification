{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc512fa6-b6be-4828-958c-29c4f7a33d4b",
   "metadata": {},
   "source": [
    "# Brief Summary of The Classifiers In The Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2944dba-6803-4548-a735-f9d2f1a8a0c8",
   "metadata": {},
   "source": [
    "In terms of accuracy, the decision tree classifier is the most accurate followed by the MiniRocket classifier then followed by the ResNet50 convolutional neural network which was applied to the chi square maps. Both the MiniRocket and ResNet50 do not require feature engineering from the user prior to their use which is an advantage they hold over the decision tree.\n",
    "\n",
    "The decision tree and MiniRocket in particular consistently have accuracies over 90% despite the smaller sample size of the data used to train them in comparison to the data available. The reason for the use of a smaller sample size is due to a need to balance the data between sources classified as transients and non-transients to minimise bias within the classifiers.\n",
    "\n",
    "Additionally, MiniRocket and ResNet50 have been capable of predicting outliers which the decision tree cannot which is another advantage they hold.\n",
    "\n",
    "To cover as many likely transient candidates, this pipeline obtains predicted transients from each classifier and groups them into 1 large dataframe. Limitations in the pipeline aside from the natural limitations of each classifier pertain to the fact that the light curves, fits cubes and feature data do not have a direct correspondence between each other. For instance there may be sources in the feature data for which we are missing light curves or fits cubes so we are unable to classify those sources in one or more of the classifiers.\n",
    "\n",
    "Nonetheless, these 3 different classifiers should aid in reducing the amount of sources that a researcher of such transient phenomena would need to examine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897df0d-f5a7-466c-8df2-17f9c3616939",
   "metadata": {},
   "source": [
    "# Import The Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e052bf-3ed0-4e67-aec8-22809f6a83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af25741-3800-428a-b321-15d446ab0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This keeps the seed for keras and tensorflow consistent across scripts\n",
    "from numpy.random import seed \n",
    "# keras seed fixing import\n",
    "seed(1)\n",
    "\n",
    "# tensorflow seed fixing\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335a9c2f-be15-43bb-9559-a96f564884cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sktime.utils import mlflow_sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb237a1-ca6e-433b-ad38-b8b13982f15c",
   "metadata": {},
   "source": [
    "# Obtain and Preprocess The Data For Each Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a528842-fad6-43cc-8b52-cd7d475ec178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data file name to whichever data file you are using\n",
    "data_file_name = \"All_Transient_Data.csv\"\n",
    "\n",
    "# Folder names\n",
    "lc_folder_name = \"VAST 10s lightcurve\"\n",
    "fits_folder_name = \"VAST 10s fitscube\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11ac3f5-8f7a-4c25-a454-ec4df337eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = pd.read_csv(data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d606168-ff58-4465-b9ce-ba8083a3c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the transient data with the light curve paths and the fits file paths\n",
    "rel_data = t_data[[\"sbid\",\"beam\",\"name\"]]\n",
    "rel_data = rel_data.dropna(how='any',axis=0)\n",
    "rel_data[\"sbid\"] = rel_data[\"sbid\"].astype(str)\n",
    "rel_data[\"lc_peakflux_path\"] = \"SB\"+rel_data[\"sbid\"]+\"_\"+rel_data[\"beam\"]+\"_lightcurve_peak_flux.csv\"\n",
    "\n",
    "rel_data[\"fits_path\"] = \"SB\"+rel_data[\"sbid\"]+\"_\"+rel_data[\"beam\"]+\"_slices_\"+rel_data[\"name\"]+\".fits\"\n",
    "\n",
    "all_lc_files = os.listdir(lc_folder_name)\n",
    "\n",
    "# Collect the light curve paths in the data subset that actually exist\n",
    "match_files = []\n",
    "for i in list(rel_data[\"lc_peakflux_path\"].unique()):\n",
    "    if i in all_lc_files:\n",
    "        match_files.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99325a-fa49-4400-91a9-a8286dba2840",
   "metadata": {},
   "source": [
    "### Preprocessing For Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c19562-327a-43d4-92e1-cede944fe6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Replaces infinite values with 1,000,000 and replaces NaN values with the column's median.\n",
    "    This is only done for particular columns of interest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe we want to process\n",
    "\n",
    "    feature_cols : list\n",
    "        List of strings og features or columns in the data that we want to process.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        The processed dataframe.\n",
    "    \"\"\"\n",
    "    # Replace inf values with large floats so the classifier can use the value\n",
    "    # Choice of 1E6 because it is much larger than the maximum values of columns with inf as a value.\n",
    "    df[feature_cols] = df[feature_cols].replace(np.inf, float(1E6))\n",
    "\n",
    "    # Replace NaN values with the median\n",
    "    df[feature_cols] = df[feature_cols].fillna(df[feature_cols].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d742067-6711-4923-bc38-db0d9cf74aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data for decision tree\n",
    "feature_cols = ['chi_square', 'chi_square_sigma', 'peak_map', 'peak_map_sigma','md_deep', 'deep_sep_arcsec', \n",
    "                'deep_num', 'bright_sep_arcmin', 'beam_sep_deg', 'deep_peak_flux', 'deep_int_flux','std_map']\n",
    "dt_data = process_data(t_data, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da784713-0b56-4809-ae57-b2eeae12d0be",
   "metadata": {},
   "source": [
    "### Preprocessing For MiniRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f9d788-85dd-465d-b0b2-0649f3e50423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies min-max normalisation on an array or signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : list or numpy array\n",
    "        A list or array of integers or floats.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    signal : numpy array\n",
    "        A min-max normalised numpy array\n",
    "    \"\"\"\n",
    "    # Min-max normalisation so values are in between 0 and 1\n",
    "    signal = np.array(signal)\n",
    "    signal = (signal - signal.min())/ (signal.max() - signal.min())\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901a3239-ffee-4d7e-8f91-692319efb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data_seq(file_name, rel_data, lc_folder_name, min_seq_size = 64):\n",
    "    \"\"\"\n",
    "    Obtains the truncated sequences and source information for each source\n",
    "    in a light curve file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        The name of the file with it's extension.\n",
    "\n",
    "    rel_data : pandas dataframe\n",
    "        The dataframe containing the relevant features and\n",
    "        associated peak flux light curve paths.\n",
    "\n",
    "    lc_folder_name : str, \"VAST 10s lightcurve\"\n",
    "        The path to the light curve folder\n",
    "\n",
    "    min_seq_size : int, default = 64\n",
    "        The minimum length of the sequences which restricts how large\n",
    "        the other sequences can be.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sequences : list\n",
    "        List of all the obtained light curves.\n",
    "\n",
    "    src_names : list\n",
    "        List of all the obtained source information for the light curves.\n",
    "    \"\"\"\n",
    "    pf_df = pd.read_csv(f\"{lc_folder_name}/{file_name}\")\n",
    "    \n",
    "    split_file = file_name.split(\"_\")\n",
    "    sbid = split_file[0][2:]\n",
    "    beam_id = split_file[1]\n",
    "    sequences = []\n",
    "    src_names = []\n",
    "    for src in pf_df.columns[1:]:\n",
    "        # Need to denoise the signals\n",
    "        val = pf_df[src].values\n",
    "        \n",
    "        # Need to normalise row values\n",
    "        val = normalise_signal(val)\n",
    "        # truncate the rows so all rows are the same size\n",
    "        val = val[:min_seq_size]\n",
    "        val = list(val)\n",
    "        src_names.append(f\"{sbid}_{beam_id}_{src}\")\n",
    "        sequences.append(val)\n",
    "\n",
    "    return sequences, src_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bf40fbc-208f-4f9e-b7c2-faada7f327be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the sequences and source information from the light curve file\n",
    "all_sequences = []\n",
    "all_src_names = []\n",
    "for file in match_files:\n",
    "    sequences, src_names =  obtain_data_seq(file, rel_data, lc_folder_name, min_seq_size = 64)\n",
    "    all_sequences.extend(sequences)\n",
    "    all_src_names.extend(src_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d274de7-aa1a-470e-868e-3cefe8360776",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_array = np.array(all_sequences)\n",
    "src_array = np.array(all_src_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f47df7e-ce31-4a42-a735-bcd52942ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "src_array = src_array[~np.isnan(seq_array).any(axis=1)]\n",
    "seq_array = seq_array[~np.isnan(seq_array).any(axis=1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1afbbe8c-e4d6-4e9e-9abb-ddb7a2e4393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sequences a numpy 3D array for the rocket classifier\n",
    "seq_array = seq_array[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d21766-ec9d-4b3d-af3f-67b4116fc9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2525, 1, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d64c2-abcc-438e-89af-084f57866328",
   "metadata": {},
   "source": [
    "### Preprocessing for ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a34b5c6-afa5-4d0a-9d9e-027403c4f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_avail_fits(rel_data, fits_folder_name):\n",
    "    \"\"\"\n",
    "    Obtains the fits files which are in both the given dataframe\n",
    "    and the fits folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rel_data : pandas dataframe\n",
    "        The dataframe with all the possible fits paths.\n",
    "\n",
    "    fits_folder_name : string, default \"VAST 10s fitscube\"\n",
    "        The fits folder path.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    avail_fits : list\n",
    "        A list of strings of the selected fits file names.\n",
    "    \"\"\"\n",
    "    # List of files in fits_folder and the actual data\n",
    "    avail_fits = []\n",
    "\n",
    "    for file in os.listdir(fits_folder_name):\n",
    "        if file in rel_data[\"fits_path\"].unique():\n",
    "            avail_fits.append(file)\n",
    "\n",
    "    return avail_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a787d59e-e39b-42eb-bc42-87f3346ecabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_rms(fits_path, lc_folder_name):\n",
    "    \"\"\"\n",
    "    Obtains the local root mean squared data for a particular fits file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_path : str\n",
    "        The path for a fits file.\n",
    "\n",
    "    lc_folder_name : str\n",
    "        The path for a light curve folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rms : numpy array\n",
    "        An array containing the local root mean squared values for a particular array.\n",
    "    \"\"\"\n",
    "    # Need to return indices which have rms = 0 or nan\n",
    "    sbid, beam, _, name = fits_path.split(\"_\")\n",
    "    name = name[:-5]\n",
    "    rms_path = f\"{sbid}_{beam}_lightcurve_local_rms.csv\"\n",
    "\n",
    "    # Need to ensure that a light curve exists \n",
    "    if rms_path not in os.listdir(lc_folder_name):\n",
    "        return np.array([])\n",
    "    else:\n",
    "        local_rms_df = pd.read_csv(f\"{lc_folder_name}//{rms_path}\")\n",
    "        rms = local_rms_df[name]\n",
    "        rms = np.array(rms)\n",
    "        rms = rms[:, np.newaxis, np.newaxis]\n",
    "        return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2e6540-54ba-42bc-af62-abc98e51a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cube(fits_path, fits_folder_name):\n",
    "    \"\"\"\n",
    "    Obtains a 3D fits cube with values relating to images taken at different\n",
    "    time points during an observation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_path : str\n",
    "        The path for a fits file.\n",
    "\n",
    "    lc_folder_name : str\n",
    "        The path for a light curve folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cube : numpy array\n",
    "        A 3D fits cube corresponding to the given fits file.\n",
    "    \"\"\"\n",
    "    # Only take slices which do not have a corresponding rms equal to 0\n",
    "    hdu = fits.open(fits_folder_name+\"/\"+fits_path)\n",
    "    cube = hdu[0].data\n",
    "\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92522a2-6605-45b7-9d4c-605b965b1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_csm(cube, rms):\n",
    "    \"\"\"\n",
    "    Obstains the chi square maps for\n",
    "    a particular fits cube.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube : numpy array\n",
    "        A fits cube containing images of a particular observation\n",
    "        at different time points.\n",
    "\n",
    "    rms : numpy array\n",
    "        The local rms of the associated cube.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chisq_array : numpy array\n",
    "        The chi square map for the input fits cube.\n",
    "    \"\"\"\n",
    "    # number of freedom\n",
    "    nu = cube.shape[0] - 1\n",
    "    mean = np.nanmean(cube, axis=0)\n",
    "    \n",
    "    data = (cube - mean) / rms\n",
    "    chisq_array = np.sum(np.power(data, 2), axis=0)/nu\n",
    "\n",
    "    # normalise the array\n",
    "    chisq_array = normalise_signal(chisq_array)\n",
    "    chisq_array = np.repeat(chisq_array[...,np.newaxis], 3, -1)\n",
    "    \n",
    "    return chisq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f7f2d3-3c0f-44a9-aac2-2c250165039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the available fits files\n",
    "avail_fits = obtain_avail_fits(rel_data, fits_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8104aa5-fa99-4665-a9d6-a4565d932c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the available fits paths such that only those which have a valid local rms file are obtained\n",
    "adj_avail_fits = []\n",
    "for i, fits_path in enumerate(avail_fits):\n",
    "        rms = obtain_rms(fits_path, lc_folder_name)\n",
    "        # if there is no corresponding rms curve for a fits file, skip this iteration\n",
    "        if rms.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Only if the rms values do not contain nan values will I obtain the cube\n",
    "        if not np.isnan(rms).any():\n",
    "            adj_avail_fits.append(avail_fits[i])\n",
    "\n",
    "adj_avail_fits = np.array(adj_avail_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfbb79e5-febd-486d-a114-fd2a7a45f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter fits files based on valid cube data and peak maps which pass a threshold\n",
    "map_size = (120,120)\n",
    "\n",
    "# Indices where the cube's shape is not what we expect from the map size\n",
    "invalid_idx = []\n",
    "\n",
    "for i, fits_path in enumerate(adj_avail_fits):\n",
    "        rms = obtain_rms(fits_path, lc_folder_name)\n",
    "        # Take the first non-zero value onwards\n",
    "        first_non_zero_idx = np.argmax(rms != 0)\n",
    "        rms = rms[first_non_zero_idx:,:,:]\n",
    "        cube = obtain_cube(fits_path, fits_folder_name)\n",
    "        cube = cube[first_non_zero_idx:,:,:]\n",
    "    \n",
    "        if (cube.shape[1:] != map_size):\n",
    "            invalid_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50d4285a-ee24-4f50-911b-f07c4e526098",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_avail_fits = np.delete(adj_avail_fits, invalid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ebee4eb-ffa2-4aee-9ab0-4daf59937b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all the chi-square maps\n",
    "\n",
    "num_channels = 3\n",
    "\n",
    "# Initialise a numpy array to store the chi-square maps\n",
    "all_csm = np.zeros((len(adj_avail_fits), map_size[0], map_size[1], num_channels))\n",
    "for i, fits_path in enumerate(adj_avail_fits):\n",
    "    rms = obtain_rms(fits_path, lc_folder_name)\n",
    "    # Take the first non-zero value onwards\n",
    "    first_non_zero_idx = np.argmax(rms != 0)\n",
    "    rms = rms[first_non_zero_idx:,:,:]\n",
    "    cube = obtain_cube(fits_path, fits_folder_name)\n",
    "    cube = cube[first_non_zero_idx:,:,:]\n",
    "    # Obtain the chi squared maps\n",
    "    csm = obtain_csm(cube, rms)\n",
    "    all_csm[i,:,:,:] = csm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124da2ca-1279-44d2-928f-7fbd0a737354",
   "metadata": {},
   "source": [
    "# *Decision Tree Predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebdc257f-c239-4349-b812-0bfb741870c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the decision tree classifier\n",
    "tree_path = \"Models/Tree_clf/Tree.pkl\"\n",
    "with open(tree_path, \"rb\") as f:\n",
    "    tree_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dd5bd02-be63-424f-a249-a9b6517f5b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>name</th>\n",
       "      <th>ra_str</th>\n",
       "      <th>dec_str</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>chi_square</th>\n",
       "      <th>chi_square_log_sigma</th>\n",
       "      <th>chi_square_sigma</th>\n",
       "      <th>peak_map</th>\n",
       "      <th>...</th>\n",
       "      <th>beam</th>\n",
       "      <th>sbid</th>\n",
       "      <th>PSR_name</th>\n",
       "      <th>PSR_sep</th>\n",
       "      <th>dyspec</th>\n",
       "      <th>KNOWN_name</th>\n",
       "      <th>KNOWN_sep</th>\n",
       "      <th>PSR_name_int</th>\n",
       "      <th>KNOWN_name_int</th>\n",
       "      <th>PSR_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>J163259.92-501507.22</td>\n",
       "      <td>16:32:59.92</td>\n",
       "      <td>-50:15:07.22</td>\n",
       "      <td>248.249681</td>\n",
       "      <td>-50.252004</td>\n",
       "      <td>2.874275</td>\n",
       "      <td>6.047280</td>\n",
       "      <td>7.511542</td>\n",
       "      <td>4.286386</td>\n",
       "      <td>...</td>\n",
       "      <td>beam00</td>\n",
       "      <td>49588</td>\n",
       "      <td>J1633-5015</td>\n",
       "      <td>1.934309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J163048.20-491129.49</td>\n",
       "      <td>16:30:48.20</td>\n",
       "      <td>-49:11:29.49</td>\n",
       "      <td>247.700817</td>\n",
       "      <td>-49.191524</td>\n",
       "      <td>2.465644</td>\n",
       "      <td>5.211199</td>\n",
       "      <td>6.240665</td>\n",
       "      <td>3.523429</td>\n",
       "      <td>...</td>\n",
       "      <td>beam00</td>\n",
       "      <td>49588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>J162710.82-481537.04</td>\n",
       "      <td>16:27:10.82</td>\n",
       "      <td>-48:15:37.04</td>\n",
       "      <td>246.795077</td>\n",
       "      <td>-48.260289</td>\n",
       "      <td>3.333277</td>\n",
       "      <td>6.090706</td>\n",
       "      <td>8.813457</td>\n",
       "      <td>3.578227</td>\n",
       "      <td>...</td>\n",
       "      <td>beam04</td>\n",
       "      <td>49588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>J163250.42-482506.53</td>\n",
       "      <td>16:32:50.42</td>\n",
       "      <td>-48:25:06.53</td>\n",
       "      <td>248.210091</td>\n",
       "      <td>-48.418480</td>\n",
       "      <td>3.578913</td>\n",
       "      <td>5.044124</td>\n",
       "      <td>9.465821</td>\n",
       "      <td>4.424191</td>\n",
       "      <td>...</td>\n",
       "      <td>beam05</td>\n",
       "      <td>49588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>J164019.07-490047.32</td>\n",
       "      <td>16:40:19.07</td>\n",
       "      <td>-49:00:47.32</td>\n",
       "      <td>250.079454</td>\n",
       "      <td>-49.013143</td>\n",
       "      <td>3.547815</td>\n",
       "      <td>5.492090</td>\n",
       "      <td>9.384754</td>\n",
       "      <td>4.350268</td>\n",
       "      <td>...</td>\n",
       "      <td>beam06</td>\n",
       "      <td>49588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id                  name       ra_str       dec_str          ra  \\\n",
       "0          0  J163259.92-501507.22  16:32:59.92  -50:15:07.22  248.249681   \n",
       "1          1  J163048.20-491129.49  16:30:48.20  -49:11:29.49  247.700817   \n",
       "2          0  J162710.82-481537.04  16:27:10.82  -48:15:37.04  246.795077   \n",
       "3          0  J163250.42-482506.53  16:32:50.42  -48:25:06.53  248.210091   \n",
       "4          0  J164019.07-490047.32  16:40:19.07  -49:00:47.32  250.079454   \n",
       "\n",
       "         dec  chi_square  chi_square_log_sigma  chi_square_sigma  peak_map  \\\n",
       "0 -50.252004    2.874275              6.047280          7.511542  4.286386   \n",
       "1 -49.191524    2.465644              5.211199          6.240665  3.523429   \n",
       "2 -48.260289    3.333277              6.090706          8.813457  3.578227   \n",
       "3 -48.418480    3.578913              5.044124          9.465821  4.424191   \n",
       "4 -49.013143    3.547815              5.492090          9.384754  4.350268   \n",
       "\n",
       "   ...    beam   sbid    PSR_name   PSR_sep  dyspec  KNOWN_name  KNOWN_sep  \\\n",
       "0  ...  beam00  49588  J1633-5015  1.934309     NaN         NaN        NaN   \n",
       "1  ...  beam00  49588         NaN       NaN     NaN         NaN        NaN   \n",
       "2  ...  beam04  49588         NaN       NaN     NaN         NaN        NaN   \n",
       "3  ...  beam05  49588         NaN       NaN     NaN         NaN        NaN   \n",
       "4  ...  beam06  49588         NaN       NaN     NaN         NaN        NaN   \n",
       "\n",
       "   PSR_name_int  KNOWN_name_int  PSR_Label  \n",
       "0             1               0          1  \n",
       "1             0               0          0  \n",
       "2             0               0          0  \n",
       "3             0               0          0  \n",
       "4             0               0          0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "591248f7-313c-475f-a006-5031e53d4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the classifier for predictions on the new data\n",
    "tree_preds = tree_clf.predict(dt_data[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "401af092-8954-48a2-8740-0792db0e16c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7714,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59993374-c70e-4cba-930e-40247bffbabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([7080,  634], dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tree_preds, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de8cc51f-ada9-4a3f-8252-043051a65954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from source names, sbid and beam id.\n",
    "tree_cand_df = dt_data.iloc[tree_preds == 1][['sbid','beam','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d6fb52-e104-4480-9c65-5a90666d141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbid</th>\n",
       "      <th>beam</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam00</td>\n",
       "      <td>J163259.92-501507.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam17</td>\n",
       "      <td>J163037.34-473302.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam06</td>\n",
       "      <td>J165148.70-424609.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam06</td>\n",
       "      <td>J164946.18-423017.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam07</td>\n",
       "      <td>J165148.76-424611.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sbid    beam                  name\n",
       "0   49588  beam00  J163259.92-501507.22\n",
       "13  49588  beam17  J163037.34-473302.59\n",
       "15  49589  beam06  J165148.70-424609.76\n",
       "16  49589  beam06  J164946.18-423017.80\n",
       "17  49589  beam07  J165148.76-424611.17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_cand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04bd43-bd22-4fa7-9bf9-094ee476b108",
   "metadata": {},
   "source": [
    "# *MiniRocket Predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de26fb89-b3a4-4ca4-9409-0da88fb6b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the minirocket classifier\n",
    "rocket_path = f\"Models/Rocket_Model\"\n",
    "rocket_clf = mlflow_sktime.load_model(model_uri=rocket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d4f660c-ffb4-4434-bad6-6743dd3929c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the classifier for predictions on the new sequences\n",
    "rocket_preds = rocket_clf.predict(seq_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2710073d-c947-463a-a321-f8a86380b7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2060,  465], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rocket_preds, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0924b543-df2c-46a5-9d08-f3e3e2ba8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain srcs\n",
    "rocket_cand_srcs = src_array[rocket_preds == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54268cca-ab6f-4d06-bd5b-bcf93bb92b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the sbid, beam and names of the sources\n",
    "rocket_sbid = []\n",
    "rocket_beam = []\n",
    "rocket_name = []\n",
    "for src in rocket_cand_srcs:\n",
    "    sbid, beam, name = src.split(\"_\")\n",
    "    rocket_sbid.append(int(sbid))\n",
    "    rocket_beam.append(beam)\n",
    "    rocket_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a001955-deda-4442-b795-7327c38dc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary\n",
    "rocket_cand_dict = {\"sbid\":rocket_sbid, \"beam\":rocket_beam, \"name\":rocket_name}\n",
    "rocket_cand_df = pd.DataFrame(rocket_cand_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1af385f8-adcd-41fe-a45f-0c17726a600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbid</th>\n",
       "      <th>beam</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60802</td>\n",
       "      <td>beam15</td>\n",
       "      <td>J174556.28-304022.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60802</td>\n",
       "      <td>beam19</td>\n",
       "      <td>J175258.66-280637.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam08</td>\n",
       "      <td>J174802.33-244636.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam17</td>\n",
       "      <td>J173326.43-222845.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam26</td>\n",
       "      <td>J175258.73-280636.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sbid    beam                  name\n",
       "0  60802  beam15  J174556.28-304022.46\n",
       "1  60802  beam19  J175258.66-280637.15\n",
       "2  60803  beam08  J174802.33-244636.78\n",
       "3  60803  beam17  J173326.43-222845.82\n",
       "4  60803  beam26  J175258.73-280636.72"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocket_cand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd7cbb-74c7-4c2a-8449-5118dd1e92fc",
   "metadata": {},
   "source": [
    "# *Chi-Square Map ResNet Predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ef9e944-7082-47a4-b5fd-80dd36683065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best hyper parameters in a dictionary\n",
    "fpath = \"Models/CSM_Resnet\"\n",
    "with open(f\"{fpath}/hyperparams.pkl\", \"rb\") as f:\n",
    "    hp_dict = pickle.load(f)\n",
    "\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1c3e221-bf13-493f-b01f-5d2edd6e8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = keras.Sequential()\n",
    "        \n",
    "input_shape = (map_size[0], map_size[1], num_channels)\n",
    "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
    "                   input_shape=input_shape,\n",
    "                   pooling='avg',classes=n_classes,\n",
    "                   weights='imagenet')\n",
    "\n",
    "# Don't train the pretrained layers\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(units=hp_dict['units'], activation='relu'))\n",
    "# Choose sigmoid activation for binary classification\n",
    "resnet_model.add(Dense(n_classes, activation='sigmoid'))\n",
    "#resnet_model.build((None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "\n",
    "# Choose binary crossentropy loss function for binary classification\n",
    "resnet_model.compile(optimizer=Adam(learning_rate = hp_dict['learning_rate']),loss='binary_crossentropy',metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e58a8ab4-eb9a-4afd-a8ae-8d1c045b2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on all_csm\n",
    "resnet_model.load_weights(f\"{fpath}/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff1b8200-1bfb-48ad-bb07-d8411c0f2a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 6s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "resnet_preds = resnet_model.predict(all_csm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93ae5691-283a-4685-928c-2a65bece631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_preds_decoded = []\n",
    "for pred in resnet_preds:\n",
    "    resnet_preds_decoded.append(np.argmax(pred))\n",
    "resnet_preds_decoded = np.array(resnet_preds_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6e24f7f-a514-404c-b544-723d980aa0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([2021,  461], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine how many of each class is predicted\n",
    "np.unique(resnet_preds_decoded, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "090373e1-ca65-4a2b-9cf1-7875efd5effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain relevant src_info\n",
    "cand_fits_files = adj_avail_fits[resnet_preds_decoded == 1]\n",
    "resnet_sbid = []\n",
    "resnet_beam = []\n",
    "resnet_name = []\n",
    "for file in cand_fits_files:\n",
    "    sbid, beam, _, name = file.split(\"_\")\n",
    "    resnet_sbid.append(int(sbid[2:]))\n",
    "    resnet_beam.append(beam)\n",
    "    resnet_name.append(name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c974dfa-fa61-4107-977f-e22ddd1476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from these values\n",
    "resnet_cand_dict = {\"sbid\":resnet_sbid, \"beam\":resnet_beam, \"name\": resnet_name}\n",
    "resnet_cand_df = pd.DataFrame(resnet_cand_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6f8c492-531d-4eaa-88a6-d0da00ff4319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbid</th>\n",
       "      <th>beam</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60802</td>\n",
       "      <td>beam15</td>\n",
       "      <td>J174556.28-304022.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60802</td>\n",
       "      <td>beam19</td>\n",
       "      <td>J175258.66-280637.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam08</td>\n",
       "      <td>J174802.33-244636.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam17</td>\n",
       "      <td>J173326.43-222845.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60803</td>\n",
       "      <td>beam26</td>\n",
       "      <td>J175258.73-280636.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sbid    beam                  name\n",
       "0  60802  beam15  J174556.28-304022.46\n",
       "1  60802  beam19  J175258.66-280637.15\n",
       "2  60803  beam08  J174802.33-244636.78\n",
       "3  60803  beam17  J173326.43-222845.82\n",
       "4  60803  beam26  J175258.73-280636.72"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_cand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53291fc-a710-4b81-a3a7-772729ab8488",
   "metadata": {},
   "source": [
    "### Issue With The Loaded ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26f089-9371-40d5-8100-6d3995e75d11",
   "metadata": {},
   "source": [
    "When the saved ResNet model from the 'Chi_Square_Map_and_Peak_Map_ResNet' notebook is loaded in a new notebook, the predictions on the same set of data may differ each time this notebook is run. Attempted solutions included setting the accuracy metric in the ResNet architecture of both notebooks to 'binary_accuracy', setting a seed for the keras and tensorflow, stopping the random shuffling and saving the entire model and loading it in this notebook.\n",
    "\n",
    "None of these methods have worked in addressing this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e9b40-eeb8-485b-95b6-738797c876db",
   "metadata": {},
   "source": [
    "# Collect All The Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "123d1748-363e-4ca3-a169-371e07a841b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the candidates into 1 dataframe.\n",
    "cand_df = pd.concat([tree_cand_df, rocket_cand_df, resnet_cand_df], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f06d2bac-21b2-4bb5-91bc-6c0ec50d0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the duplicate rows\n",
    "cand_df.drop_duplicates(inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b897801-0ae5-454f-b652-fbcd2ec03052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbid</th>\n",
       "      <th>beam</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam00</td>\n",
       "      <td>J163259.92-501507.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam17</td>\n",
       "      <td>J163037.34-473302.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam06</td>\n",
       "      <td>J165148.70-424609.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam06</td>\n",
       "      <td>J164946.18-423017.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49589</td>\n",
       "      <td>beam07</td>\n",
       "      <td>J165148.76-424611.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sbid    beam                  name\n",
       "0  49588  beam00  J163259.92-501507.22\n",
       "1  49588  beam17  J163037.34-473302.59\n",
       "2  49589  beam06  J165148.70-424609.76\n",
       "3  49589  beam06  J164946.18-423017.80\n",
       "4  49589  beam07  J165148.76-424611.17"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11e4468a-39ad-4a6d-9b9f-d00a062e34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the candidates\n",
    "cand_fol = \"Transient_candidates\"\n",
    "cand_df.to_csv(f\"{cand_fol}/transient_candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d6cf5-1e04-44a9-87d4-3c689d8ae4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
