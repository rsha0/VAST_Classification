{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a3927b-eb9c-444e-b4e2-079bfd66788d",
   "metadata": {},
   "source": [
    "# Import The Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71be2e16-84aa-4014-9bd3-0a5aead161ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "from astropy.io import fits\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26a937-9487-45e7-9847-904f1cf26feb",
   "metadata": {},
   "source": [
    "# Obtain and Process Relevant VAST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5819def1-2d0a-4c43-a643-f5cca3c5f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = pd.read_csv(\"All_Transient_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bb66dd-bd2f-47ab-80f4-ce67955ad6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_id', 'name', 'ra_str', 'dec_str', 'ra', 'dec', 'chi_square',\n",
       "       'chi_square_log_sigma', 'chi_square_sigma', 'peak_map',\n",
       "       'peak_map_log_sigma', 'peak_map_sigma', 'gaussian_map',\n",
       "       'gaussian_map_sigma', 'std_map', 'md_deep', 'deep_sep_arcsec',\n",
       "       'deep_num', 'bright_sep_arcmin', 'beam_sep_deg', 'beam_ra', 'beam_dec',\n",
       "       'deep_name', 'deep_ra_deg', 'deep_dec_deg', 'deep_peak_flux',\n",
       "       'deep_int_flux', 'priority', 'lightcurve', 'deepcutout', 'slices',\n",
       "       'chisq_map2', 'peak_map2', 'beam', 'sbid', 'PSR_name', 'PSR_sep',\n",
       "       'dyspec', 'KNOWN_name', 'KNOWN_sep', 'PSR_name_int', 'KNOWN_name_int',\n",
       "       'PSR_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8877e0-31a2-4089-a13c-c7c3132577a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_data = t_data[[\"sbid\",\"beam\",\"name\",\"peak_map_sigma\",\"PSR_Label\"]]\n",
    "# Remove all null_values\n",
    "rel_data = rel_data.dropna(how='any',axis=0)\n",
    "\n",
    "# Obtain Corresponding fits paths\n",
    "rel_data[\"sbid\"] = rel_data[\"sbid\"].astype(str)\n",
    "rel_data[\"fits_path\"] = \"SB\"+rel_data[\"sbid\"]+\"_\"+rel_data[\"beam\"]+\"_slices_\"+rel_data[\"name\"]+\".fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccf4340-2658-41cd-89dd-a2d5224ea646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbid</th>\n",
       "      <th>beam</th>\n",
       "      <th>name</th>\n",
       "      <th>peak_map_sigma</th>\n",
       "      <th>PSR_Label</th>\n",
       "      <th>fits_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam00</td>\n",
       "      <td>J163259.92-501507.22</td>\n",
       "      <td>3.226517</td>\n",
       "      <td>1</td>\n",
       "      <td>SB49588_beam00_slices_J163259.92-501507.22.fits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam00</td>\n",
       "      <td>J163048.20-491129.49</td>\n",
       "      <td>2.178119</td>\n",
       "      <td>0</td>\n",
       "      <td>SB49588_beam00_slices_J163048.20-491129.49.fits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam04</td>\n",
       "      <td>J162710.82-481537.04</td>\n",
       "      <td>2.259193</td>\n",
       "      <td>0</td>\n",
       "      <td>SB49588_beam04_slices_J162710.82-481537.04.fits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam05</td>\n",
       "      <td>J163250.42-482506.53</td>\n",
       "      <td>3.402407</td>\n",
       "      <td>0</td>\n",
       "      <td>SB49588_beam05_slices_J163250.42-482506.53.fits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49588</td>\n",
       "      <td>beam06</td>\n",
       "      <td>J164019.07-490047.32</td>\n",
       "      <td>3.308430</td>\n",
       "      <td>0</td>\n",
       "      <td>SB49588_beam06_slices_J164019.07-490047.32.fits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sbid    beam                  name  peak_map_sigma  PSR_Label  \\\n",
       "0  49588  beam00  J163259.92-501507.22        3.226517          1   \n",
       "1  49588  beam00  J163048.20-491129.49        2.178119          0   \n",
       "2  49588  beam04  J162710.82-481537.04        2.259193          0   \n",
       "3  49588  beam05  J163250.42-482506.53        3.402407          0   \n",
       "4  49588  beam06  J164019.07-490047.32        3.308430          0   \n",
       "\n",
       "                                         fits_path  \n",
       "0  SB49588_beam00_slices_J163259.92-501507.22.fits  \n",
       "1  SB49588_beam00_slices_J163048.20-491129.49.fits  \n",
       "2  SB49588_beam04_slices_J162710.82-481537.04.fits  \n",
       "3  SB49588_beam05_slices_J163250.42-482506.53.fits  \n",
       "4  SB49588_beam06_slices_J164019.07-490047.32.fits  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4119f8a2-8a3d-4560-8340-f3f7489a4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_avail_fits(rel_data, fits_folder_name = \"VAST 10s fitscube\", outlier_to_test = False, outlier_fname = None):\n",
    "    \"\"\"\n",
    "    Obtains the fits files and labels which are in both the given dataframe\n",
    "    and the fits folder. If the user wants to assign a particular\n",
    "    outlier to the testing data later, they can set outlier_to_test to be True\n",
    "    and give the outlier's filename.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rel_data : pandas dataframe\n",
    "        The dataframe with all the possible fits paths.\n",
    "\n",
    "    fits_folder_name : string, default \"VAST 10s fitscube\"\n",
    "        The fits folder path.\n",
    "\n",
    "    outlier_to_test : bool, default False\n",
    "        Whether the user wants to push a particular outlier to the testing set.\n",
    "\n",
    "    outlier_fname : string, default None\n",
    "        The filename of the outlier.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    avail_fits : list\n",
    "        A list of strings of the selected fits file names.\n",
    "\n",
    "    fits_labels : list\n",
    "        A list of integers of the labels for the selected fits file names.\n",
    "\n",
    "    outlier : dict\n",
    "        A dictionary which maps the outlier's file name to its label.\n",
    "    \"\"\"\n",
    "    # List of files in fits_folder and the actual data\n",
    "    avail_fits = []\n",
    "    # List of fits_labels\n",
    "    fits_labels = []\n",
    "    outlier = {}\n",
    "    if outlier_to_test:\n",
    "        \n",
    "        for file in os.listdir(fits_folder_name):\n",
    "            if file in rel_data[\"fits_path\"].unique():\n",
    "                if file == outlier_fname:\n",
    "                    outlier[outlier_fname] = rel_data[rel_data[\"fits_path\"]==outlier_fname][\"PSR_Label\"].item()\n",
    "                else:\n",
    "                    avail_fits.append(file)\n",
    "                    fits_labels.append(rel_data[rel_data[\"fits_path\"]==file][\"PSR_Label\"].item())\n",
    "    else:\n",
    "        for file in os.listdir(fits_folder_name):\n",
    "            if file in rel_data[\"fits_path\"].unique():\n",
    "                avail_fits.append(file)\n",
    "                fits_labels.append(rel_data[rel_data[\"fits_path\"]==file][\"PSR_Label\"].item())\n",
    "\n",
    "    return avail_fits, fits_labels, outlier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce867921-7c9d-4174-a6fc-78a8be87a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a particular outlier to the test data\n",
    "outlier_to_test = False\n",
    "outlier_fname = \"SB62644_beam19_slices_J183248.46-091115.92.fits\"\n",
    "\n",
    "# Finding the available fits files\n",
    "avail_fits, fits_labels, outlier = obtain_avail_fits(rel_data, outlier_to_test = outlier_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9262ca-be58-4198-926a-b5939173c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_labels = np.array(fits_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "778cb384-f92a-4840-8e51-c07205a5cb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2267,  252], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(fits_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1944a-fe7b-46d6-81b6-d763c192719e",
   "metadata": {},
   "source": [
    "# Obtain A Balanced Number of Fits Files and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd8fd96-5fe6-4b64-a1e3-117f149ad88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_rms(fits_path, lc_folder_name):\n",
    "    \"\"\"\n",
    "    Obtains the local root mean squared data for a particular fits file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_path : str\n",
    "        The path for a fits file.\n",
    "\n",
    "    lc_folder_name : str\n",
    "        The path for a light curve folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rms : numpy array\n",
    "        An array containing the local root mean squared values for a particular array.\n",
    "    \"\"\"\n",
    "    # Need to return indices which have rms = 0 or nan\n",
    "    sbid, beam, _, name = fits_path.split(\"_\")\n",
    "    name = name[:-5]\n",
    "    rms_path = f\"{sbid}_{beam}_lightcurve_local_rms.csv\"\n",
    "\n",
    "    # Need to ensure that a light curve exists \n",
    "    if rms_path not in os.listdir(lc_folder_name):\n",
    "        return np.array([])\n",
    "    else:\n",
    "        local_rms_df = pd.read_csv(f\"{lc_folder_name}//{rms_path}\")\n",
    "        rms = local_rms_df[name]\n",
    "        rms = np.array(rms)\n",
    "        # We need 3D rms since we will use cube / rms later.\n",
    "        rms = rms[:, np.newaxis, np.newaxis]\n",
    "        return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bea741e-2335-43d4-b444-094b275208c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cube(fits_path, fits_folder_name):\n",
    "    \"\"\"\n",
    "    Obtains a 3D fits cube with values relating to images taken at different\n",
    "    time points during an observation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_path : str\n",
    "        The path for a fits file.\n",
    "\n",
    "    lc_folder_name : str\n",
    "        The path for a light curve folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cube : numpy array\n",
    "        A 3D fits cube corresponding to the given fits file.\n",
    "    \"\"\"\n",
    "    # Only take slices which do not have a corresponding rms equal to 0\n",
    "    hdu = fits.open(fits_folder_name+\"/\"+fits_path)\n",
    "    cube = hdu[0].data\n",
    "\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da94d07e-0b37-4642-bfa6-5871f019b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rms_nan(avail_fits):\n",
    "    \"\"\"\n",
    "    Checks how many sources with fits files \n",
    "    have associated rms arrays that contain NaN values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    avail_fits : list\n",
    "        The fits files we will check.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total : int\n",
    "        The total number of sources which have rms arrays containing NaN values.\n",
    "\n",
    "    loss_cand : int\n",
    "        The number of transients lost from the data since their rms arrays contain NaN values.\n",
    "    \"\"\"\n",
    "    # Check how many rms arrays contain nan values\n",
    "    total = 0\n",
    "    \n",
    "    # Check how many detected transients have rms arrays that contain nan values\n",
    "    loss_cand = 0\n",
    "    for i, fits_path in enumerate(avail_fits):\n",
    "        rms = obtain_rms(fits_path, lc_folder_name)\n",
    "        if np.isnan(rms).any():\n",
    "            total += 1\n",
    "            if fits_labels[i] == 1:\n",
    "                loss_cand += 1\n",
    "                print(fits_path)\n",
    "\n",
    "    return total, loss_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "831c6cb7-074b-4fce-abc0-923ee407b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zero_idx(avail_fits):\n",
    "    \"\"\"\n",
    "    Find the indices of the zeros in the \n",
    "    rms arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    avail_fits : list\n",
    "        The fits files we will examine.\n",
    "    \"\"\"\n",
    "    for i, fits_path in enumerate(avail_fits):\n",
    "            rms = obtain_rms(fits_path, lc_folder_name)\n",
    "            zero_idx = np.where(rms == 0)[0]\n",
    "            if zero_idx.size != 0:\n",
    "                print(zero_idx)\n",
    "                # All zeros occur at the start so just take the first non-zero value onwards\n",
    "                print(np.argmax(rms != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f53535-a5c7-44a7-be0e-adedcbe46c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_folder_name = \"VAST 10s lightcurve\"\n",
    "fits_folder_name = \"VAST 10s fitscube\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1910e919-4b9c-4b8d-afbc-f0dad030d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.65091586112976\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Filter fits files and labels based on valid rms data\n",
    "start = time.time()\n",
    "adj_fits_labels = []\n",
    "adj_avail_fits = []\n",
    "for i, fits_path in enumerate(avail_fits):\n",
    "        rms = obtain_rms(fits_path, lc_folder_name)\n",
    "        # if there is no corresponding rms curve for a fits file, skip this iteration\n",
    "        if rms.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Only obtain the cube if the rms values do not contain nan values\n",
    "        if not np.isnan(rms).any():\n",
    "            adj_fits_labels.append(fits_labels[i])\n",
    "            adj_avail_fits.append(avail_fits[i])\n",
    "\n",
    "adj_fits_labels = np.array(adj_fits_labels)\n",
    "adj_avail_fits = np.array(adj_avail_fits)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65036c8f-c396-42e1-931d-8e4462445d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.65484046936035\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Filter fits files and labels based on valid cube data\n",
    "map_size = (120,120)\n",
    "\n",
    "# Invalid indices\n",
    "invalid_idx = []\n",
    "\n",
    "for i, fits_path in enumerate(adj_avail_fits):\n",
    "        rms = obtain_rms(fits_path, lc_folder_name)\n",
    "        # Take the first non-zero value onwards\n",
    "        first_non_zero_idx = np.argmax(rms != 0)\n",
    "        rms = rms[first_non_zero_idx:,:,:]\n",
    "        cube = obtain_cube(fits_path, fits_folder_name)\n",
    "        cube = cube[first_non_zero_idx:,:,:]\n",
    "        if (cube.shape[1:] != map_size):\n",
    "            invalid_idx.append(i)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a98366-48f3-42aa-823d-bc9d25a403e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_fits_labels = np.delete(adj_fits_labels, invalid_idx)\n",
    "adj_avail_fits = np.delete(adj_avail_fits, invalid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df428570-796f-4b19-8af3-961728b01730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "2224\n"
     ]
    }
   ],
   "source": [
    "# See the number of each label as a way to determine the degree of imbalance in the dataset\n",
    "print(sum(adj_fits_labels == 1))\n",
    "print(sum(adj_fits_labels == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bc52e-4a35-4f43-a8c9-86d0d1609341",
   "metadata": {},
   "source": [
    "### Balancing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7728bff-1e54-4b6d-8897-018b519a7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_bal_fpaths_labels(adj_avail_fits, adj_fits_labels, outlier = None, outlier_to_test = False):\n",
    "    \"\"\"\n",
    "    Obtains a collection of fits paths and associated labels\n",
    "    that are balanced so there are the same number of\n",
    "    each of the unique labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adj_avail_fits : numpy array\n",
    "        The fits paths that we need to balance.\n",
    "\n",
    "    adj_avail_fits_labels : numpy array\n",
    "        The labels that we need to balance.\n",
    "\n",
    "    outlier : dict, default None\n",
    "        A dictionary that has mapped an outlier's file name\n",
    "        to its label.\n",
    "\n",
    "    outlier_to_test : bool, False\n",
    "        The user decides whether to send the outlier to the test data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_fits_paths : numpy array\n",
    "        The final balanced collection of fits paths.\n",
    "\n",
    "    final_labels : numpy array\n",
    "        The final balanced collection of labels.\n",
    "    \"\"\"\n",
    "    # Indices of transients/ positive candidates\n",
    "    pos_idx_ls = np.where(adj_fits_labels == 1)[0]\n",
    "    # Indices of non transients/ negative candidates\n",
    "    neg_idx_ls = np.where(adj_fits_labels == 0)[0]\n",
    "    num_rand_vals = len(pos_idx_ls)\n",
    "    \n",
    "    # Obtain num_rand_vals+1 to account for a particular outlier\n",
    "    if outlier_to_test:\n",
    "        reduced_neg_idx_ls = np.random.choice(neg_idx_ls, num_rand_vals+1, replace = False)\n",
    "    else:\n",
    "        reduced_neg_idx_ls = np.random.choice(neg_idx_ls, num_rand_vals, replace = False)\n",
    "\n",
    "    # Use the indices of the fits labels and fits paths list to shuffle them\n",
    "    idx_ls = np.concatenate([pos_idx_ls, reduced_neg_idx_ls])\n",
    "    # Randomise the indices:\n",
    "    shuffled_idx_ls = np.random.choice(idx_ls, len(idx_ls), replace = False)\n",
    "\n",
    "    # Need to randomise these labels and fits paths:\n",
    "    final_labels = adj_fits_labels[shuffled_idx_ls]\n",
    "    final_fits_paths = adj_avail_fits[shuffled_idx_ls]\n",
    "    \n",
    "    # Ensures the outlier is in the test data\n",
    "    if outlier_to_test:\n",
    "        final_fits_paths = np.append(final_fits_paths, list(outlier.keys())[0])\n",
    "        final_labels = np.append(final_labels, list(outlier.values())[0])\n",
    "    \n",
    "    return final_fits_paths, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41383f8-3ac8-4129-80dc-7712f240940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fits_paths, final_labels = obtain_bal_fpaths_labels(adj_avail_fits, adj_fits_labels, outlier = outlier, outlier_to_test = outlier_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65fb7c63-ae2a-4cac-aeb6-761feca2051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fits_paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3fd7fd-4527-4ef5-bbfd-34810b014a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf019c-44f7-4822-b0b5-c1a6460965ae",
   "metadata": {},
   "source": [
    "# Obtain The Chi Square Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7134595-c95a-4f3f-8a96-7a638cf060bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_arr(arr):\n",
    "    \"\"\"\n",
    "    Applies min-max normalisation on an array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy array\n",
    "        A list or array of integers or floats.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy array\n",
    "        A min-max normalised numpy array.\n",
    "    \"\"\"\n",
    "    # Normalise the input image via min max normalisation\n",
    "    arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8466ff9-8740-4f85-993e-001588e4a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_csm(cube, rms):\n",
    "    \"\"\"\n",
    "    Obstains the chi square maps for\n",
    "    a particular fits cube.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube : numpy array\n",
    "        A fits cube containing images of a particular observation\n",
    "        at different time points.\n",
    "\n",
    "    rms : numpy array\n",
    "        The local rms of the associated cube.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chisq_array : numpy array\n",
    "        The chi square map for the input fits cube.\n",
    "    \"\"\"\n",
    "    # number of freedom\n",
    "    nu = cube.shape[0] - 1\n",
    "    mean = np.nanmean(cube, axis=0)\n",
    "    \n",
    "    data = (cube - mean) / rms\n",
    "    chisq_array = np.sum(np.power(data, 2), axis=0)/nu\n",
    "\n",
    "    # normalise the array\n",
    "    chisq_array = normalise_arr(chisq_array)\n",
    "    chisq_array = np.repeat(chisq_array[...,np.newaxis], 3, -1)\n",
    "    \n",
    "    return chisq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f48b517-f890-4aba-8e9c-80494b948b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.834362983703613\n"
     ]
    }
   ],
   "source": [
    "# Collect all the chi-square maps together\n",
    "num_channels = 3\n",
    "start = time.time()\n",
    "\n",
    "# Instantiate a numpy array to contain the chi square maps \n",
    "all_csm = np.zeros((len(final_fits_paths), map_size[0], map_size[1], num_channels))\n",
    "for i, fits_path in enumerate(final_fits_paths):\n",
    "    rms = obtain_rms(fits_path, lc_folder_name)\n",
    "    # Take the first non-zero value onwards\n",
    "    first_non_zero_idx = np.argmax(rms != 0)\n",
    "    rms = rms[first_non_zero_idx:,:,:]\n",
    "    cube = obtain_cube(fits_path, fits_folder_name)\n",
    "    cube = cube[first_non_zero_idx:,:,:]\n",
    "    # Obtain the chi squared maps\n",
    "    csm = obtain_csm(cube, rms)\n",
    "    all_csm[i,:,:,:] = csm\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16d4fa4-3ea7-4f40-a412-6be5ac593d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# check if all_csm is normalised\n",
    "print(all_csm.min())\n",
    "print(all_csm.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73454141-8286-41e5-ba58-a3397060e577",
   "metadata": {},
   "source": [
    "### Splitting Chi Square Map Data into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d57b5ae-c761-43a6-abe8-4a71709e1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(map_array, labels, train_prop = 0.7):\n",
    "    \"\"\"\n",
    "    Splits the maps and labels into training\n",
    "    and testing data according to a particular proportion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    map_array : numpy array\n",
    "        The maps that are going to be split.\n",
    "\n",
    "    labels : numpy array\n",
    "        The labels that are going to be split.\n",
    "\n",
    "    train_prop : float, default 0.7\n",
    "        The proportion of the maps and labels in\n",
    "        the training set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train : numpy array\n",
    "        The maps in the training set.\n",
    "\n",
    "    test : numpy array\n",
    "        The maps in the test set.\n",
    "\n",
    "    train_labels : numpy array\n",
    "        The labels in the training set.\n",
    "\n",
    "    test_labels : numpy array\n",
    "        The labels in the test set.\n",
    "    \"\"\"\n",
    "    # Obtain the number of training samples\n",
    "    n_train = round(map_array.shape[0] * train_prop)\n",
    "\n",
    "    # Obtaining train and test maps\n",
    "    train = map_array[:n_train+1,:]\n",
    "    test = map_array[n_train+1:,:]\n",
    "\n",
    "    # Obtaining train and test labels\n",
    "    train_labels = labels[:n_train+1]\n",
    "    test_labels = labels[n_train+1:]\n",
    "\n",
    "    return train, test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33eeef4b-00b5-4010-8ef4-d031715f0b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_maps(map_arrays, labels, data_class, data_fol):\n",
    "    \"\"\"\n",
    "    Saves the map arrays and their labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    map_arrays : numpy array\n",
    "        The map arrays you wish to save.\n",
    "\n",
    "    labels : numpy array\n",
    "        The associated labels of the map arrays.\n",
    "\n",
    "    data_class : str\n",
    "        Whether you want to save the data as \"Train\", \"Test\" or \"Validation\" data.\n",
    "\n",
    "    data_fol : str\n",
    "        The folder path you are going to save the map arrays and labels to.\n",
    "    \"\"\"\n",
    "    # Save maps data\n",
    "    f_path = f\"{data_fol}/{data_class}/{data_class}\"\n",
    "    np.save(f_path+\"_maps\", map_arrays)\n",
    "    np.save(f_path+\"_Labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f01cd934-2f4e-48f3-8729-6f7a73a384c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the chi-square maps into training and test data\n",
    "csm_train, csm_test, csm_train_labels, csm_test_labels = train_test_split(all_csm, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "511835c5-1e08-4329-88d2-5a914eee3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation\n",
    "csm_train, csm_val, csm_train_labels, csm_val_labels = train_test_split(csm_train, csm_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6540120c-4878-4346-9504-5082572dafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save chi square map data\n",
    "csm_data_fol = \"chi_square_map\"\n",
    "save_maps(csm_train, csm_train_labels, \"Train\", csm_data_fol)\n",
    "save_maps(csm_val, csm_val_labels, \"Validation\", csm_data_fol)\n",
    "save_maps(csm_test, csm_test_labels, \"Test\", csm_data_fol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd03b2-dba4-4034-b208-feda2e7cbc74",
   "metadata": {},
   "source": [
    "# Obtain The Peak Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90d955f5-7697-4568-a36c-09eeb2a8ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_pm(cube, rms):\n",
    "    \"\"\"\n",
    "    Obstains the peak maps for\n",
    "    a particular fits cube.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube : numpy array\n",
    "        A fits cube containing images of a particular observation\n",
    "        at different time points.\n",
    "\n",
    "    rms : numpy array\n",
    "        The local rms of the associated cube.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    peak_array : numpy array\n",
    "        The peak map for the input fits cube.\n",
    "    \"\"\"\n",
    "    snr = cube / rms \n",
    "    peak_array = np.nanmax(snr, axis=0) - np.median(snr, axis=0)\n",
    "    \n",
    "    # normalise the array\n",
    "    peak_array = normalise_arr(peak_array)\n",
    "    peak_array = np.repeat(peak_array[...,np.newaxis], 3, -1)\n",
    "\n",
    "    return peak_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8160e593-1def-4069-b5fc-a32508f814b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.595597505569458\n"
     ]
    }
   ],
   "source": [
    "# Collect all the peak maps together\n",
    "start = time.time()\n",
    "\n",
    "# Instantiate a numpy array to contain the peak maps \n",
    "all_pm = np.zeros((len(final_fits_paths), map_size[0], map_size[1], num_channels))\n",
    "for i, fits_path in enumerate(final_fits_paths):\n",
    "    rms = obtain_rms(fits_path, lc_folder_name)\n",
    "    # Take the first non-zero value onwards\n",
    "    first_non_zero_idx = np.argmax(rms != 0)\n",
    "    rms = rms[first_non_zero_idx:,:,:]\n",
    "    cube = obtain_cube(fits_path, fits_folder_name)\n",
    "    cube = cube[first_non_zero_idx:,:,:]\n",
    "    pm = obtain_pm(cube, rms)\n",
    "    all_pm[i,:,:,:] = pm\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "184421b1-fce6-445d-867d-dad8e241ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# check if all_pm is normalised\n",
    "print(all_pm.min())\n",
    "print(all_pm.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0568eec-a219-4804-b61e-0194d92a0dbd",
   "metadata": {},
   "source": [
    "### Splitting Peak Map Data into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d92592c-edec-4993-88d7-8967356c30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the peak maps into training and test data\n",
    "pm_train, pm_test, pm_train_labels, pm_test_labels = train_test_split(all_pm, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8476395b-7399-4ab9-88a3-43400915c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation\n",
    "pm_train, pm_val, pm_train_labels, pm_val_labels = train_test_split(pm_train, pm_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6e1dacd-fc68-491c-8330-c485d270763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save peak map data\n",
    "pm_data_fol = \"peak_map\"\n",
    "save_maps(pm_train, pm_train_labels, \"Train\", pm_data_fol)\n",
    "save_maps(pm_val, pm_val_labels, \"Validation\", pm_data_fol)\n",
    "save_maps(pm_test, pm_test_labels, \"Test\", pm_data_fol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94266edb-6811-430a-b9c2-2a1040fb9845",
   "metadata": {},
   "source": [
    "# Combine Chi-Square, Std and Peak Maps Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b18a0747-592e-4d5e-9684-bcabca04baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_csm_std_pm(cube, rms):\n",
    "    \"\"\"\n",
    "    Obstains an array which combines the chi square maps,\n",
    "    standard deviation maps and peak maps for a particular fits cube.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube : numpy array\n",
    "        A fits cube containing images of a particular observation\n",
    "        at different time points.\n",
    "\n",
    "    rms : numpy array\n",
    "        The local rms of the associated cube.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    csm_std_pm : numpy array\n",
    "        An array containing the chi square, standard deviation and peak maps for the input fits cube.\n",
    "    \"\"\"\n",
    "    # Obtain chi square map\n",
    "    \n",
    "    # Number of freedom\n",
    "    nu = cube.shape[0] - 1\n",
    "    mean = np.nanmean(cube, axis=0)\n",
    "    \n",
    "    data = (cube - mean) / rms\n",
    "    chisq_array = np.sum(np.power(data, 2), axis=0)/nu\n",
    "\n",
    "    # Normalise the array\n",
    "    chisq_array = normalise_arr(chisq_array)\n",
    "    chisq_array = chisq_array[...,np.newaxis]\n",
    "\n",
    "    # Obtain peak map\n",
    "    snr = cube / rms \n",
    "    peak_array = np.nanmax(snr, axis=0) - np.median(snr, axis=0)\n",
    "    \n",
    "    # Normalise the array\n",
    "    peak_array = normalise_arr(peak_array)\n",
    "    peak_array = peak_array[...,np.newaxis]\n",
    "\n",
    "    # Obtain std map\n",
    "    std_array = np.nanstd(cube, axis=0)\n",
    "\n",
    "    # Normalise the array\n",
    "    std_array = normalise_arr(std_array)\n",
    "    std_array = std_array[...,np.newaxis]\n",
    "\n",
    "    # Concatenate the chi square maps and peak maps together\n",
    "    csm_std_pm = np.concatenate([chisq_array, std_array, peak_array], axis=-1)\n",
    "    \n",
    "    return csm_std_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e8d229a-a24e-40e9-bfe6-09e12812f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a numpy array to contain the chi-square, std and peak maps \n",
    "all_csm_std_pm = np.zeros((len(final_fits_paths), map_size[0], map_size[1], num_channels))\n",
    "for i, fits_path in enumerate(final_fits_paths):\n",
    "    rms = obtain_rms(fits_path, lc_folder_name)\n",
    "    # Take the first non-zero value onwards\n",
    "    first_non_zero_idx = np.argmax(rms != 0)\n",
    "    rms = rms[first_non_zero_idx:,:,:]\n",
    "    cube = obtain_cube(fits_path, fits_folder_name)\n",
    "    cube = cube[first_non_zero_idx:,:,:]\n",
    "\n",
    "    # Obtain the peak maps\n",
    "    csm_std_pm = obtain_csm_std_pm(cube, rms)\n",
    "    all_csm_std_pm[i,:,:,:] = csm_std_pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde9bae-5af6-4ccf-82ea-98b7b87fc06f",
   "metadata": {},
   "source": [
    "### Splitting Chi Square, Std and Peak Map Data into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6aaad52-0121-4a50-a9e6-e760b54c3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the maps into training and test data\n",
    "csm_std_pm_train, csm_std_pm_test, csm_std_pm_train_labels, csm_std_pm_test_labels = train_test_split(all_csm_std_pm, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbd962cb-48fd-4865-913e-3569f5fc6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation\n",
    "csm_std_pm_train, csm_std_pm_val, csm_std_pm_train_labels, csm_std_pm_val_labels = train_test_split(csm_std_pm_train, csm_std_pm_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1716f4ab-1871-45cb-9c5f-86f3fafe7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map data\n",
    "csm_std_pm_data_fol = \"chi_square_std_peak_maps\"\n",
    "save_maps(csm_std_pm_train, csm_std_pm_train_labels, \"Train\", csm_std_pm_data_fol)\n",
    "save_maps(csm_std_pm_val, csm_std_pm_val_labels, \"Validation\", csm_std_pm_data_fol)\n",
    "save_maps(csm_std_pm_test, csm_std_pm_test_labels, \"Test\", csm_std_pm_data_fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98dc427c-8340-4035-822c-21bffc48d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# check if all_csm_std_pm is normalised\n",
    "print(all_csm_std_pm.max())\n",
    "print(all_csm_std_pm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8450edf-ca26-4413-8514-7c45c1bbf9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([126, 119], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(csm_train_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c0895a6-69b7-4e2b-8352-789e6fa4dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the presence of the outlier which should be the last map\n",
    "if outlier_to_test:\n",
    "    rms = obtain_rms(list(outlier.keys())[0], lc_folder_name)\n",
    "    # Take the first non-zero value onwards\n",
    "    first_non_zero_idx = np.argmax(rms != 0)\n",
    "    rms = rms[first_non_zero_idx:,:,:]\n",
    "    cube = obtain_cube(fits_path, fits_folder_name)\n",
    "    cube = cube[first_non_zero_idx:,:,:]\n",
    "    outlier_csm = obtain_csm(cube, rms)\n",
    "    # Checking if the outlier is in the test set\n",
    "    print(csm_test_labels[-1])\n",
    "    print(sum(sum(sum(outlier_csm != csm_test[-1]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
